{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from load_dataset import load_data\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instancier le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, cat_features = load_data().get_data_X_y(data='simplify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB avec Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau des performances pour différentes combinaisons d'hyperparamètres :\n",
      "  param_var_smoothing  mean_test_score  std_test_score\n",
      "0                 0.1         0.852577        0.008585\n",
      "1                0.05         0.857207        0.009911\n",
      "2               0.001         0.871392        0.011246\n",
      "3              0.0005         0.870368        0.012424\n",
      "4             0.00001         0.867265        0.010439\n",
      "5            0.000005         0.866907        0.010408\n",
      "6                 0.0         0.866907        0.010408\n",
      "7                 0.0         0.866907        0.010408\n",
      "8                 0.0         0.866907        0.010408\n"
     ]
    }
   ],
   "source": [
    "# Définir les hyperparamètres à tester\n",
    "parameters = {'var_smoothing': [1e-1, 0.5e-1, 1e-3, 0.5e-3, 1e-5, 0.5e-5, 1e-7, 0.5e-7, 1e-9]}\n",
    "\n",
    "# Initialiser le modèle Naïf Bayes Gaussien\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Utiliser GridSearchCV pour tester différents hyperparamètres\n",
    "grid_search = GridSearchCV(naive_bayes, parameters, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir les résultats de la validation croisée\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Afficher un tableau des résultats pour chaque combinaison d'hyperparamètres testée\n",
    "print(\"Tableau des performances pour différentes combinaisons d'hyperparamètres :\")\n",
    "print(results[['param_var_smoothing', 'mean_test_score', 'std_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB avec les meilleurs hyperparamètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 84.337 %\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_opt = GaussianNB(var_smoothing=0.0005)\n",
    "naive_bayes_opt.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy : {naive_bayes_opt.score(X_train, y_train) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 84.298 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy : {naive_bayes_opt.score(X_test, y_test) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78       414\n",
      "           1       0.85      0.91      0.88       675\n",
      "\n",
      "    accuracy                           0.84      1089\n",
      "   macro avg       0.84      0.82      0.83      1089\n",
      "weighted avg       0.84      0.84      0.84      1089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = naive_bayes_opt.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Naive Bayes n'est pas très informatif sur les features et leur importances.\n",
    "\n",
    "GaussianNB n'offre pas de méthode intrinsèque pour évaluer l'importance des caractéristiques. Les méthodes de Naïve Bayes fonctionnent en déterminant les probabilités conditionnelles et inconditionnelles associées aux caractéristiques et en prédisant la classe avec la probabilité la plus élevée. Ainsi, aucun coefficient n'est calculé ou associé aux caractéristiques qu'on utilise pour entraîner le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle donne quand même un bon score, mais il est peu informatif et dûr à expliquer à partir des features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
