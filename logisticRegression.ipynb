{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import utils\n",
    "from load_dataset import load_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instancier le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, cat_features = load_data().get_data_X_y(data='simplify', OneHot=True, Scaler='MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 92.326 %\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du modèle de régression logistique\n",
    "logistic_regression = LogisticRegression(C=10, max_iter=1000, solver='lbfgs', random_state=42)  # Spécification du nombre maximal d'itérations\n",
    "\n",
    "# Entraînement du modèle\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy : {logistic_regression.score(X_train, y_train) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 91.093 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy : {logistic_regression.score(X_test, y_test) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       414\n",
      "           1       0.91      0.95      0.93       675\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.91      0.90      0.90      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (approuvées)</th>\n",
       "      <td>14.602029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 1er semestre (approuvées)</th>\n",
       "      <td>10.100678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (sans évaluations)</th>\n",
       "      <td>4.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (note)</th>\n",
       "      <td>2.731695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cours_2</th>\n",
       "      <td>2.594284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (créditées)</th>\n",
       "      <td>-2.305121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 1er semestre (créditées)</th>\n",
       "      <td>-2.695534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (évaluations)</th>\n",
       "      <td>-3.198157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 1er semestre (inscrits)</th>\n",
       "      <td>-3.430284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unités curriculaires 2e semestre (inscrits)</th>\n",
       "      <td>-8.402948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance\n",
       "Unités curriculaires 2e semestre (approuvées)        14.602029\n",
       "Unités curriculaires 1er semestre (approuvées)       10.100678\n",
       "Unités curriculaires 2e semestre (sans évaluati...    4.056225\n",
       "Unités curriculaires 2e semestre (note)               2.731695\n",
       "Cours_2                                               2.594284\n",
       "...                                                        ...\n",
       "Unités curriculaires 2e semestre (créditées)         -2.305121\n",
       "Unités curriculaires 1er semestre (créditées)        -2.695534\n",
       "Unités curriculaires 2e semestre (évaluations)       -3.198157\n",
       "Unités curriculaires 1er semestre (inscrits)         -3.430284\n",
       "Unités curriculaires 2e semestre (inscrits)          -8.402948\n",
       "\n",
       "[135 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.features_importance(logistic_regression, X_train.columns, plot=False, _coef=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of different parameter combinations:\n",
      "    param_C param_solver param_max_iter  mean_test_score  std_test_score\n",
      "0     0.001    newton-cg            100         0.801427        0.007634\n",
      "1     0.001        lbfgs            100         0.801427        0.007634\n",
      "2     0.001    liblinear            100         0.800365        0.006827\n",
      "3     0.001          sag            100         0.801427        0.007634\n",
      "4     0.001         saga            100         0.801427        0.007634\n",
      "..      ...          ...            ...              ...             ...\n",
      "100    1000    newton-cg          10000         0.923779        0.009437\n",
      "101    1000        lbfgs          10000         0.923779        0.009437\n",
      "102    1000    liblinear          10000         0.923779        0.009437\n",
      "103    1000          sag          10000         0.923135        0.009540\n",
      "104    1000         saga          10000         0.924170        0.009018\n",
      "\n",
      "[105 rows x 5 columns]\n",
      "\n",
      "Best parameters: {'C': 100, 'max_iter': 100, 'solver': 'saga'}\n",
      "F1 with best parameters: 0.9253916793299585\n"
     ]
    }
   ],
   "source": [
    "#Analyse des meilleurs hyperparametres\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for testing different parameters\n",
    "grid_search = GridSearchCV(logistic_regression, parameters, cv=5, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of parameter grid search\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Print a comparative table of parameter combinations and their performance metrics\n",
    "print(\"Comparison of different parameter combinations:\")\n",
    "print(results[['param_C', 'param_solver', 'param_max_iter', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Get the best parameters and their corresponding accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_f1 = grid_search.best_score_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"F1 with best parameters: {best_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 92.523 %\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy : {model.score(X_train, y_train) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 90.909 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy : {model.score(X_test, y_test) * 100:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       414\n",
      "           1       0.91      0.95      0.93       675\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.91      0.90      0.90      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
