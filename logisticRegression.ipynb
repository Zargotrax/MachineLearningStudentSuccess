{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données des iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from CSV\n",
    "data = pd.read_csv(\"./dataset_with_dummies.csv\")\n",
    "\n",
    "# X = data.drop({'Target'}, axis=1)  # Features\n",
    "# y = data['Target']  # Target variable\n",
    "X = data.drop({'Cible'}, axis=1)  # Features\n",
    "y = data['Cible']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du modèle de régression logistique\n",
    "logistic_regression = LogisticRegression(C=10, max_iter=1000, solver='lbfgs')  # Spécification du nombre maximal d'itérations\n",
    "\n",
    "# Entraînement du modèle\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse des meilleurs hyperparametres\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [100, 1000, 10000]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for testing different parameters\n",
    "grid_search = GridSearchCV(logistic_regression, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of parameter grid search\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Print a comparative table of parameter combinations and their performance metrics\n",
    "print(\"Comparison of different parameter combinations:\")\n",
    "print(results[['param_C', 'param_solver', 'param_max_iter', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Get the best parameters and their corresponding accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Accuracy with best parameters: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation des performances du modèle\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision du modèle : {accuracy}\")\n",
    "\n",
    "# Affichage du rapport de classification et de la matrice de confusion\n",
    "print(\"Rapport de classification :\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Matrice de confusion :\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find best class weight combinaison for max accuracy\n",
    "unique_classes = data['Cible'].unique()\n",
    "\n",
    "best_accuracy = 0\n",
    "best_class_weights = None\n",
    "\n",
    "# Define different weight combinations for all classes\n",
    "weight_combinations = product([1, 5, 10], repeat=len(unique_classes))\n",
    "\n",
    "# Iterate through different weight combinations\n",
    "for weights in weight_combinations:\n",
    "    class_weights = {class_label: weight for class_label, weight in zip(unique_classes, weights)}\n",
    "\n",
    "    # Train the model using the class weights\n",
    "    logistic_regression = LogisticRegression(C=10, max_iter=1000, solver='lbfgs', class_weight=class_weights)\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy with class weights {class_weights}: {accuracy}\")\n",
    "\n",
    "    # Track the class weights that result in the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_class_weights = class_weights\n",
    "\n",
    "print(f\"Best accuracy achieved: {best_accuracy} with class weights: {best_class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion du dataset pour ajouter des colonnes dummies pour les categories\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON mapping\n",
    "with open('donnee_info.json', 'r', encoding='utf-8') as file:\n",
    "    mapping = json.load(file)\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('fr_dataset.csv')\n",
    "\n",
    "# Columns to be replaced using the JSON mapping\n",
    "columns_to_replace = [\n",
    "    \"État civil\",\n",
    "    \"Mode d'application\",\n",
    "    \"Cours\",\n",
    "    \"Présence jour/soir\",\n",
    "    \"Qualification antérieure\",\n",
    "    \"Nationalité\",\n",
    "    \"Qualification mère\",\n",
    "    \"Qualification père\",\n",
    "    \"Occupation mère\",\n",
    "    \"Occupation père\",\n",
    "    \"Déplacé\",\n",
    "    \"Besoins éducatifs spéciaux\",\n",
    "    \"Dettes\",\n",
    "    \"Frais de scolarité à jour\",\n",
    "    \"Sexe\",\n",
    "    \"Bourse\",\n",
    "    \"International\",\n",
    "    # \"Cible\"\n",
    "]\n",
    "\n",
    "# Replace integer values with string equivalents\n",
    "for column in columns_to_replace:\n",
    "    df[column] = df[column].astype(str).map(mapping[column])\n",
    "\n",
    "# Save the modified data to a new CSV file\n",
    "df.to_csv('modified_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "for column in columns_to_replace:\n",
    "    dummies = pd.get_dummies(df[column], prefix=column)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(column, axis=1, inplace=True)  # Drop the original column after creating dummies\n",
    "\n",
    "# Save the dataset with dummy columns to a new CSV file\n",
    "df.to_csv('dataset_with_dummies.csv', index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
